<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>2d4340eaad9a46fbafe488bd8ee561bb</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="loan-default-prediction" class="cell markdown"
id="1_iHEvciuTB9">
<h1><strong>Loan Default Prediction</strong></h1>
</section>
<section id="problem-definition" class="cell markdown"
id="ZKyzwpUiuTB2">
<h2><strong>Problem Definition</strong></h2>
<h3 id="the-context"><strong>The Context:</strong></h3>
<ul>
<li>Why is this problem important to solve?</li>
</ul>
<p>Predicting loan defaults is vital for banks, particularly in adhering
to the Equal Credit Opportunity Act's guidelines, as a significant
portion of their profits is derived from home loans. Automating this
process through machine learning enhances efficiency and aligns with
industry trends, promoting data-driven and equitable credit assessment
practices.</p>
<h3 id="the-objective"><strong>The objective:</strong></h3>
<ul>
<li>What is the intended goal?</li>
</ul>
<p>The intended goal is to develop a classification model capable of
predicting clients likely to default on their loans, following the
guidelines of the Equal Credit Opportunity Act, and to provide the bank
with actionable recommendations based on key features for more informed
loan approval decisions.</p>
<h3 id="the-key-questions"><strong>The key questions:</strong></h3>
<ul>
<li>What are the key questions that need to be answered?</li>
</ul>
<p>The key questions involve assessing the model's accuracy in
predicting loan defaults, its compliance with the Equal Credit
Opportunity Act guidelines for fair loan approval, and understanding the
key features influencing predictions. Additionally, we need to evaluate
the relevance of the recommendations provided by the model to the bank
for making informed loan approval decisions and assess the model's
interpretability for justifying adverse behaviors or rejections in the
loan approval process.</p>
<h3 id="the-problem-formulation"><strong>The problem
formulation</strong>:</h3>
<ul>
<li>What is it that we are trying to solve using data science?</li>
</ul>
<p>The objective is to employ data science for predicting loan defaults
in home equity loans, utilizing various classification models such as
Logistic Regression, Decision Trees, and Random Forests. The goal is to
determine the most effective model, adhering to the guidelines of the
Equal Credit Opportunity Act, to enhance the efficiency and accuracy of
loan approval decisions for risk management and financial stability.</p>
</section>
<section id="data-description" class="cell markdown" id="qEHRGpcdo-KO">
<h2><strong>Data Description:</strong></h2>
<p>The Home Equity dataset (HMEQ) contains baseline and loan performance
information for 5,960 recent home equity loans. The target (BAD) is a
binary variable that indicates whether an applicant has ultimately
defaulted or has been severely delinquent. This adverse outcome occurred
in 1,189 cases (20 percent). 12 input variables were registered for each
applicant.</p>
<ul>
<li><p><strong>BAD:</strong> 1 = Client defaulted on loan, 0 = loan
repaid</p></li>
<li><p><strong>LOAN:</strong> Amount of loan approved.</p></li>
<li><p><strong>MORTDUE:</strong> Amount due on the existing
mortgage.</p></li>
<li><p><strong>VALUE:</strong> Current value of the property.</p></li>
<li><p><strong>REASON:</strong> Reason for the loan request. (HomeImp =
home improvement, DebtCon= debt consolidation which means taking out a
new loan to pay off other liabilities and consumer debts)</p></li>
<li><p><strong>JOB:</strong> The type of job that loan applicant has
such as manager, self, etc.</p></li>
<li><p><strong>YOJ:</strong> Years at present job.</p></li>
<li><p><strong>DEROG:</strong> Number of major derogatory reports (which
indicates a serious delinquency or late payments).</p></li>
<li><p><strong>DELINQ:</strong> Number of delinquent credit lines (a
line of credit becomes delinquent when a borrower does not make the
minimum required payments 30 to 60 days past the day on which the
payments were due).</p></li>
<li><p><strong>CLAGE:</strong> Age of the oldest credit line in
months.</p></li>
<li><p><strong>NINQ:</strong> Number of recent credit
inquiries.</p></li>
<li><p><strong>CLNO:</strong> Number of existing credit lines.</p></li>
<li><p><strong>DEBTINC:</strong> Debt-to-income ratio (all your monthly
debt payments divided by your gross monthly income. This number is one
way lenders measure your ability to manage the monthly payments to repay
the money you plan to borrow.</p></li>
</ul>
</section>
<section id="import-the-necessary-libraries-and-data"
class="cell markdown" id="DcZcGaZruTB-">
<h2><strong>Import the necessary libraries and Data</strong></h2>
</section>
<div class="cell code" data-execution_count="2" id="pvj9AGJtuTB_">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>sns.set_theme()</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report,accuracy_score,precision_score,recall_score,f1_score</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> BaggingClassifier</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="3" id="sqSN6kXpu60d">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>hm<span class="op">=</span>pd.read_csv(<span class="st">&quot;hmeq.csv&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>data<span class="op">=</span>hm.copy()</span></code></pre></div>
</div>
<section id="data-overview" class="cell markdown" id="T9ykJzCRuTCD">
<h2><strong>Data Overview</strong></h2>
</section>
<div class="cell markdown" id="DLgLExFVBZtg">
<ul>
<li>Reading the dataset</li>
<li>Understanding the shape of the dataset</li>
<li>Checking the data types</li>
<li>Checking for missing values</li>
<li>Checking for duplicated values</li>
</ul>
</div>
<div class="cell code" data-execution_count="4"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="za7znZ1cBZtg" data-outputId="71f5dff1-e324-40a2-c113-7726873fa8ec">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reading the dataset</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>hm <span class="op">=</span> pd.read_csv(<span class="st">&quot;hmeq.csv&quot;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Displaying the first few rows</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;First Few Rows:&quot;</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hm.head())</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Displaying the last few rows</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Last Few Rows:&quot;</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hm.tail())</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Understanding the shape of the dataset</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Shape of the dataset:&quot;</span>, hm.shape)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking the data types</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Data Types:&quot;</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hm.dtypes)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking for missing values</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Missing Values:&quot;</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hm.isnull().<span class="bu">sum</span>())</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking for duplicated values</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Duplicated Values:&quot;</span>, hm.duplicated().<span class="bu">sum</span>())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>First Few Rows:
   BAD  LOAN  MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  \
0    1  1100  25860.0   39025.0  HomeImp   Other  10.5    0.0     0.0   
1    1  1300  70053.0   68400.0  HomeImp   Other   7.0    0.0     2.0   
2    1  1500  13500.0   16700.0  HomeImp   Other   4.0    0.0     0.0   
3    1  1500      NaN       NaN      NaN     NaN   NaN    NaN     NaN   
4    0  1700  97800.0  112000.0  HomeImp  Office   3.0    0.0     0.0   

        CLAGE  NINQ  CLNO  DEBTINC  
0   94.366667   1.0   9.0      NaN  
1  121.833333   0.0  14.0      NaN  
2  149.466667   1.0  10.0      NaN  
3         NaN   NaN   NaN      NaN  
4   93.333333   0.0  14.0      NaN  

Last Few Rows:
      BAD   LOAN  MORTDUE    VALUE   REASON    JOB   YOJ  DEROG  DELINQ  \
5955    0  88900  57264.0  90185.0  DebtCon  Other  16.0    0.0     0.0   
5956    0  89000  54576.0  92937.0  DebtCon  Other  16.0    0.0     0.0   
5957    0  89200  54045.0  92924.0  DebtCon  Other  15.0    0.0     0.0   
5958    0  89800  50370.0  91861.0  DebtCon  Other  14.0    0.0     0.0   
5959    0  89900  48811.0  88934.0  DebtCon  Other  15.0    0.0     0.0   

           CLAGE  NINQ  CLNO    DEBTINC  
5955  221.808718   0.0  16.0  36.112347  
5956  208.692070   0.0  15.0  35.859971  
5957  212.279697   0.0  15.0  35.556590  
5958  213.892709   0.0  16.0  34.340882  
5959  219.601002   0.0  16.0  34.571519  

Shape of the dataset: (5960, 13)

Data Types:
BAD          int64
LOAN         int64
MORTDUE    float64
VALUE      float64
REASON      object
JOB         object
YOJ        float64
DEROG      float64
DELINQ     float64
CLAGE      float64
NINQ       float64
CLNO       float64
DEBTINC    float64
dtype: object

Missing Values:
BAD           0
LOAN          0
MORTDUE     518
VALUE       112
REASON      252
JOB         279
YOJ         515
DEROG       708
DELINQ      580
CLAGE       308
NINQ        510
CLNO        222
DEBTINC    1267
dtype: int64

Duplicated Values: 0
</code></pre>
</div>
</div>
<section id="summary-statistics" class="cell markdown"
id="rHTODkjLuTCT">
<h2>Summary Statistics</h2>
</section>
<div class="cell code" data-execution_count="5"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="9hRbpzF0BZth" data-outputId="e6af251a-1447-4597-bae0-d441b22a6ef3">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Summary Statistics:&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hm.describe())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Summary Statistics:
               BAD          LOAN        MORTDUE          VALUE          YOJ  \
count  5960.000000   5960.000000    5442.000000    5848.000000  5445.000000   
mean      0.199497  18607.969799   73760.817200  101776.048741     8.922268   
std       0.399656  11207.480417   44457.609458   57385.775334     7.573982   
min       0.000000   1100.000000    2063.000000    8000.000000     0.000000   
25%       0.000000  11100.000000   46276.000000   66075.500000     3.000000   
50%       0.000000  16300.000000   65019.000000   89235.500000     7.000000   
75%       0.000000  23300.000000   91488.000000  119824.250000    13.000000   
max       1.000000  89900.000000  399550.000000  855909.000000    41.000000   

             DEROG       DELINQ        CLAGE         NINQ         CLNO  \
count  5252.000000  5380.000000  5652.000000  5450.000000  5738.000000   
mean      0.254570     0.449442   179.766275     1.186055    21.296096   
std       0.846047     1.127266    85.810092     1.728675    10.138933   
min       0.000000     0.000000     0.000000     0.000000     0.000000   
25%       0.000000     0.000000   115.116702     0.000000    15.000000   
50%       0.000000     0.000000   173.466667     1.000000    20.000000   
75%       0.000000     0.000000   231.562278     2.000000    26.000000   
max      10.000000    15.000000  1168.233561    17.000000    71.000000   

           DEBTINC  
count  4693.000000  
mean     33.779915  
std       8.601746  
min       0.524499  
25%      29.140031  
50%      34.818262  
75%      39.003141  
max     203.312149  
</code></pre>
</div>
</div>
<div class="cell markdown" id="g51vGZAGuTCT">
<ul>
<li>Observations from Summary Statistics</li>
</ul>
</div>
<section id="exploratory-data-analysis-eda-and-visualization"
class="cell markdown" id="3ZcMbNvZuTCW">
<h2><strong>Exploratory Data Analysis (EDA) and
Visualization</strong></h2>
</section>
<div class="cell markdown" id="_Td9x7DdBZti">
<ul>
<li>EDA is an important part of any project involving data.</li>
<li>It is important to investigate and understand the data better before
building a model with it.</li>
<li>A few questions have been mentioned below which will help you
approach the analysis in the right manner and generate insights from the
data.</li>
<li>A thorough analysis of the data, in addition to the questions
mentioned below, should be done.</li>
</ul>
</div>
<div class="cell markdown" id="ba_dqV0sBZti">
<p><strong>Leading Questions</strong>:</p>
<ol>
<li>What is the range of values for the loan amount variable
"LOAN"?</li>
<li>How does the distribution of years at present job "YOJ" vary across
the dataset?</li>
<li>How many unique categories are there in the REASON variable?</li>
<li>What is the most common category in the JOB variable?</li>
<li>Is there a relationship between the REASON variable and the
proportion of applicants who defaulted on their loan?</li>
<li>Do applicants who default have a significantly different loan amount
compared to those who repay their loan?</li>
<li>Is there a correlation between the value of the property and the
loan default rate?</li>
<li>Do applicants who default have a significantly different mortgage
amount compared to those who repay their loan?</li>
</ol>
</div>
<section id="univariate-analysis" class="cell markdown"
id="65yxFJFVuTCW">
<h3><strong>Univariate Analysis</strong></h3>
</section>
<div class="cell code" data-execution_count="6"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:677}"
id="2zXcgmBeBZti" data-outputId="2f7c964e-ade6-4f6b-9120-9e50bac32ae5">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Univariate Analysis</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Range of Loan Amount (&quot;LOAN&quot;)</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>loan_range <span class="op">=</span> hm[<span class="st">&#39;LOAN&#39;</span>].<span class="bu">max</span>() <span class="op">-</span> hm[<span class="st">&#39;LOAN&#39;</span>].<span class="bu">min</span>()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Range of Loan Amount (LOAN):&quot;</span>, loan_range)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution of Years at Present Job (&quot;YOJ&quot;)</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>sns.histplot(hm[<span class="st">&#39;YOJ&#39;</span>].dropna(), bins<span class="op">=</span><span class="dv">20</span>, kde<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">&#39;skyblue&#39;</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Distribution of Years at Present Job (YOJ)&#39;</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Years at Present Job&#39;</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Frequency&#39;</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of Unique Categories in &quot;REASON&quot; Variable</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>unique_reason_categories <span class="op">=</span> hm[<span class="st">&#39;REASON&#39;</span>].nunique()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Number of Unique Categories in REASON:&quot;</span>, unique_reason_categories)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Most Common Category in &quot;JOB&quot; Variable</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>most_common_job_category <span class="op">=</span> hm[<span class="st">&#39;JOB&#39;</span>].mode().values[<span class="dv">0</span>]</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Most Common Category in JOB:&quot;</span>, most_common_job_category)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Range of Loan Amount (LOAN): 88800
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_2ed47a1d11e044b584584c139645e3e8/7aa2bf5883c781f4f10bd7fd695531f6ce4b48d1.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Number of Unique Categories in REASON: 2

Most Common Category in JOB: Other
</code></pre>
</div>
</div>
<section id="bivariate-analysis" class="cell markdown"
id="jg5IFtbouTCa">
<h3><strong>Bivariate Analysis</strong></h3>
</section>
<div class="cell code" data-execution_count="7"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="9b60NSTMBZtj" data-outputId="94df07fc-c78e-49e3-c42b-9a5a3029d3a7">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bivariate Analysis</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Relationship between &quot;REASON&quot; and Loan Default Rate</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>reason_default_rate <span class="op">=</span> hm.groupby(<span class="st">&#39;REASON&#39;</span>)[<span class="st">&#39;BAD&#39;</span>].mean()</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Relationship between REASON and Loan Default Rate:&quot;</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(reason_default_rate)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparison of Loan Amounts for Defaulters and Repayers</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>sns.boxplot(x<span class="op">=</span><span class="st">&#39;BAD&#39;</span>, y<span class="op">=</span><span class="st">&#39;LOAN&#39;</span>, data<span class="op">=</span>hm)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Comparison of Loan Amounts for Defaulters and Repayers&#39;</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Loan Status (BAD)&#39;</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loan Amount&#39;</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation between Property Value and Loan Default Rate</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>correlation_value_default <span class="op">=</span> hm[<span class="st">&#39;VALUE&#39;</span>].corr(hm[<span class="st">&#39;BAD&#39;</span>])</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Correlation between Property Value and Loan Default Rate:&quot;</span>, correlation_value_default)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparison of Mortgage Amounts for Defaulters and Repayers</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>sns.boxplot(x<span class="op">=</span><span class="st">&#39;BAD&#39;</span>, y<span class="op">=</span><span class="st">&#39;MORTDUE&#39;</span>, data<span class="op">=</span>hm)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Comparison of Mortgage Amounts for Defaulters and Repayers&#39;</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Loan Status (BAD)&#39;</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Mortgage Amount&#39;</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Relationship between REASON and Loan Default Rate:
REASON
DebtCon    0.189664
HomeImp    0.222472
Name: BAD, dtype: float64
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_2ed47a1d11e044b584584c139645e3e8/8a3529fc436223f4d9a2e03a7a89196bd3163bed.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Correlation between Property Value and Loan Default Rate: -0.02995368911059241
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_2ed47a1d11e044b584584c139645e3e8/996f968d465cc6065f0f801e9632f918fa463bff.png" /></p>
</div>
</div>
<section id="multivariate-analysis" class="cell markdown"
id="pc9wZJcGuTCm">
<h3><strong>Multivariate Analysis</strong></h3>
</section>
<div class="cell code" data-execution_count="9"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="nLk0Fgx-BZtj" data-outputId="79e76e8a-722d-4576-b1ff-8eb1196d2003">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Multivariate Analysis</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparison of Loan Amounts Across Job Categories</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">8</span>))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>sns.boxplot(x<span class="op">=</span><span class="st">&#39;JOB&#39;</span>, y<span class="op">=</span><span class="st">&#39;LOAN&#39;</span>, hue<span class="op">=</span><span class="st">&#39;BAD&#39;</span>, data<span class="op">=</span>hm)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Comparison of Loan Amounts Across Job Categories&#39;</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Job Category&#39;</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loan Amount&#39;</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">&#39;Loan Status (BAD)&#39;</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Effect of Derogatory Reports and Delinquent Credit Lines on Loan Default Rate</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">&#39;DEROG&#39;</span>, y<span class="op">=</span><span class="st">&#39;DELINQ&#39;</span>, hue<span class="op">=</span><span class="st">&#39;BAD&#39;</span>, data<span class="op">=</span>hm)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Effect of Derogatory Reports and Delinquent Credit Lines on Loan Default Rate&#39;</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Number of Derogatory Reports&#39;</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Number of Delinquent Credit Lines&#39;</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">&#39;Loan Status (BAD)&#39;</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Loan Default Rate Across Reason and Job Categories</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">8</span>))</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span><span class="st">&#39;REASON&#39;</span>, hue<span class="op">=</span><span class="st">&#39;JOB&#39;</span>, data<span class="op">=</span>hm, hue_order<span class="op">=</span>hm[<span class="st">&#39;JOB&#39;</span>].value_counts().index)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Loan Default Rate Across Reason and Job Categories&#39;</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Reason for Loan&#39;</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Count&#39;</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">&#39;Job Category&#39;</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_2ed47a1d11e044b584584c139645e3e8/d531617ab5974e49e3022a09059f51828b8df072.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_2ed47a1d11e044b584584c139645e3e8/793461e901bed98e241209ebc37fe17eb14a38a0.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_2ed47a1d11e044b584584c139645e3e8/feaf46b2ebbc609c1c74f33c9a86be49849867e7.png" /></p>
</div>
</div>
<section id="treating-outliers" class="cell markdown" id="zEjMlq0quTCp">
<h2>Treating Outliers</h2>
</section>
<div class="cell code" data-execution_count="10"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="WTtFHgKTBZtj" data-outputId="c9c4a9ed-2e3c-400f-d115-a35e377aa105">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> zscore</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Copy the original data to preserve the original dataset</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>hm_outlier_treated <span class="op">=</span> hm.copy()</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify and treat outliers using the Z-score method</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>z_scores <span class="op">=</span> zscore(hm_outlier_treated[[<span class="st">&#39;LOAN&#39;</span>, <span class="st">&#39;MORTDUE&#39;</span>, <span class="st">&#39;VALUE&#39;</span>]])</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>outlier_mask <span class="op">=</span> (z_scores <span class="op">&gt;</span> <span class="dv">3</span>) <span class="op">|</span> (z_scores <span class="op">&lt;</span> <span class="op">-</span><span class="dv">3</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace outliers with NaN</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>hm_outlier_treated[[<span class="st">&#39;LOAN&#39;</span>, <span class="st">&#39;MORTDUE&#39;</span>, <span class="st">&#39;VALUE&#39;</span>]] <span class="op">=</span> np.where(outlier_mask, np.nan, hm_outlier_treated[[<span class="st">&#39;LOAN&#39;</span>, <span class="st">&#39;MORTDUE&#39;</span>, <span class="st">&#39;VALUE&#39;</span>]])</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for missing values after treating outliers</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Missing Values after Treating Outliers:&quot;</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hm_outlier_treated.isnull().<span class="bu">sum</span>())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Missing Values after Treating Outliers:
BAD           0
LOAN         95
MORTDUE     518
VALUE       112
REASON      252
JOB         279
YOJ         515
DEROG       708
DELINQ      580
CLAGE       308
NINQ        510
CLNO        222
DEBTINC    1267
dtype: int64
</code></pre>
</div>
</div>
<section id="treating-missing-values" class="cell markdown"
id="U8CEq24hBZtj">
<h2>Treating Missing Values</h2>
</section>
<div class="cell code" data-execution_count="11"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="CDYGPOlXBZtk" data-outputId="be4db409-1ff0-473e-a654-82c7944170b1">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Copy the dataset to preserve the original data</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>hm_missing_treated <span class="op">=</span> hm_outlier_treated.copy()</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute missing values in numerical columns with the mean</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>numerical_cols <span class="op">=</span> [<span class="st">&#39;LOAN&#39;</span>, <span class="st">&#39;MORTDUE&#39;</span>, <span class="st">&#39;VALUE&#39;</span>, <span class="st">&#39;YOJ&#39;</span>, <span class="st">&#39;DEROG&#39;</span>, <span class="st">&#39;DELINQ&#39;</span>, <span class="st">&#39;CLAGE&#39;</span>, <span class="st">&#39;NINQ&#39;</span>, <span class="st">&#39;CLNO&#39;</span>, <span class="st">&#39;DEBTINC&#39;</span>]</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>imputer_numerical <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">&#39;mean&#39;</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>hm_missing_treated[numerical_cols] <span class="op">=</span> imputer_numerical.fit_transform(hm_missing_treated[numerical_cols])</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute missing values in categorical columns with the mode</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> [<span class="st">&#39;REASON&#39;</span>, <span class="st">&#39;JOB&#39;</span>]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>imputer_categorical <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">&#39;most_frequent&#39;</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>hm_missing_treated[categorical_cols] <span class="op">=</span> imputer_categorical.fit_transform(hm_missing_treated[categorical_cols])</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if there are any remaining missing values</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Missing Values after Imputation:&quot;</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hm_missing_treated.isnull().<span class="bu">sum</span>())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Missing Values after Imputation:
BAD        0
LOAN       0
MORTDUE    0
VALUE      0
REASON     0
JOB        0
YOJ        0
DEROG      0
DELINQ     0
CLAGE      0
NINQ       0
CLNO       0
DEBTINC    0
dtype: int64
</code></pre>
</div>
</div>
<section id="important-insights-from-eda" class="cell markdown"
id="eG_XM04vuTCs">
<h2><strong>Important Insights from EDA</strong></h2>
<p>What are the the most important observations and insights from the
data based on the EDA performed?</p>
</section>
<div class="cell markdown" id="FPTLN1k_zwvR">
<p>Loan Amount Range: The dataset exhibits a diverse range of loan
amounts ("LOAN"), spanning from the minimum to the maximum loan
values.</p>
<p>Distribution of Years at Present Job: Variability is observed in the
distribution of the number of years applicants have spent in their
current jobs ("YOJ"). Some applicants show higher job stability, while
others have less stability.</p>
<p>Reason for Loan and Job Categories: The "REASON" variable contains
various categories indicating different reasons for loan requests, such
as home improvement or debt consolidation. Additionally, the "JOB"
variable represents diverse job categories.</p>
<p>Most Common Job Category: An analysis identifies the most prevalent
job category ("JOB") in the dataset.</p>
<p>Relationship between Reason and Default Rate: The relationship
between the reason for the loan and the proportion of applicants who
defaulted on their loans is explored. This analysis aims to unveil if
certain types of loan requests are associated with higher default
rates.</p>
<p>Comparison of Loan Amounts for Defaulters and Repayers: A box plot is
utilized to compare loan amounts for applicants who defaulted and those
who repaid their loans. This visualization offers insights into
potential differences in loan amounts between the two groups.</p>
<p>Correlation between Property Value and Default Rate: The correlation
between the value of the property ("VALUE") and the loan default rate is
investigated. This analysis aims to understand whether property value is
correlated with the likelihood of default.</p>
<p>Comparison of Mortgage Amounts for Defaulters and Repayers: Another
box plot is used to compare mortgage amounts for applicants who
defaulted and those who repaid their loans. This visualization sheds
light on potential differences in mortgage amounts.</p>
<p>Multivariate Analysis: Relationships between multiple variables are
explored. This includes loan amounts across job categories, the impact
of derogatory reports and delinquent credit lines on the loan default
rate, and the loan default rate across different combinations of
"REASON" and "JOB" categories.</p>
<p>Outlier Treatment and Missing Value Imputation: Outliers in
loan-related variables are addressed, and missing values are imputed
using appropriate strategies.</p>
</div>
<section id="model-building---approach" class="cell markdown"
id="Cdqhtr8yuS-L">
<h2><strong>Model Building - Approach</strong></h2>
<ul>
<li>Data preparation</li>
<li>Partition the data into train and test set</li>
<li>Build the model</li>
<li>Fit on the train data</li>
<li>Tune the model</li>
<li>Test the model on test set</li>
</ul>
</section>
<section id="logistic-regression" class="cell markdown"
id="2CGW7uh5BZtk">
<h3>Logistic Regression</h3>
</section>
<div class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="fs0QKb4ABZtk" data-outputId="44b46505-61a4-4858-f008-17840a6591f7">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score, confusion_matrix</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Preparation</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume X and y are your features and target variable</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace &#39;your_target_column&#39; with the actual name of your target column</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> hm_missing_treated.drop(<span class="st">&#39;BAD&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> hm_missing_treated[<span class="st">&#39;BAD&#39;</span>]</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Categorical Variable Encoding (if needed)</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Example using pandas get_dummies for one-hot encoding</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>X_encoded <span class="op">=</span> pd.get_dummies(X, columns<span class="op">=</span>[<span class="st">&#39;REASON&#39;</span>, <span class="st">&#39;JOB&#39;</span>], drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Train-Test Split</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_encoded, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature Scaling (if needed)</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the Logistic Regression Model</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>logreg_model <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Model on the Training Data</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>logreg_model.fit(X_train_scaled, y_train)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the Model on the Test Set</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> logreg_model.predict(X_test_scaled)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the Model</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Logistic Regression Model Evaluation:&quot;</span>)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Accuracy:&quot;</span>, accuracy_score(y_test, y_pred))</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Confusion Matrix:&quot;</span>)</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, y_pred))</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Classification Report:&quot;</span>)</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Logistic Regression Model Evaluation:
Accuracy: 0.8162751677852349

Confusion Matrix:
[[891  36]
 [183  82]]

Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.96      0.89       927
           1       0.69      0.31      0.43       265

    accuracy                           0.82      1192
   macro avg       0.76      0.64      0.66      1192
weighted avg       0.80      0.82      0.79      1192

</code></pre>
</div>
</div>
<section id="decision-tree" class="cell markdown" id="9oYAeptGBZtk">
<h3>Decision Tree</h3>
</section>
<div class="cell code" data-execution_count="13"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="nfvaEVqsBZtk" data-outputId="d945ae47-c218-4439-eb52-d7fe820b9085">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Preparation</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume X and y are your features and target variable</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace &#39;your_target_column&#39; with the actual name of your target column</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Train-Test Split</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_encoded, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature Scaling (if needed)</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the Decision Tree Model</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>decision_tree_model <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Model on the Training Data</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>decision_tree_model.fit(X_train_scaled, y_train)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the Model on the Test Set</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>y_pred_dt <span class="op">=</span> decision_tree_model.predict(X_test_scaled)</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the Model</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Decision Tree Model Evaluation:&quot;</span>)</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Accuracy:&quot;</span>, accuracy_score(y_test, y_pred_dt))</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Confusion Matrix:&quot;</span>)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, y_pred_dt))</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Classification Report:&quot;</span>)</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_dt))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Decision Tree Model Evaluation:
Accuracy: 0.8649328859060402

Confusion Matrix:
[[858  69]
 [ 92 173]]

Classification Report:
              precision    recall  f1-score   support

           0       0.90      0.93      0.91       927
           1       0.71      0.65      0.68       265

    accuracy                           0.86      1192
   macro avg       0.81      0.79      0.80      1192
weighted avg       0.86      0.86      0.86      1192

</code></pre>
</div>
</div>
<section id="decision-tree---hyperparameter-tuning"
class="cell markdown" id="HdO4E2btpoPD">
<h3><strong>Decision Tree - Hyperparameter Tuning</strong></h3>
<ul>
<li>Hyperparameter tuning is tricky in the sense that <strong>there is
no direct way to calculate how a change in the hyperparameter value will
reduce the loss of your model</strong>, so we usually resort to
experimentation. We'll use Grid search to perform hyperparameter
tuning.</li>
<li><strong>Grid search is a tuning technique that attempts to compute
the optimum values of hyperparameters.</strong></li>
<li><strong>It is an exhaustive search</strong> that is performed on the
specific parameter values of a model.</li>
<li>The parameters of the estimator/model used to apply these methods
are <strong>optimized by cross-validated grid-search</strong> over a
parameter grid.</li>
</ul>
<p><strong>Criterion {gini, entropy}</strong></p>
<p>The function to measure the quality of a split. Supported criteria
are gini for the Gini impurity and entropy for the information
gain.</p>
<p><strong>max_depth</strong></p>
<p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
<p><strong>min_samples_leaf</strong></p>
<p>The minimum number of samples is required to be at a leaf node. A
split point at any depth will only be considered if it leaves at least
min_samples_leaf training samples in each of the left and right
branches. This may have the effect of smoothing the model, especially in
regression.</p>
<p>You can learn about more Hyperpapameters on this link and try to tune
them.</p>
<p><a
href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
class="uri">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</a></p>
</section>
<section id="building-a-random-forest-classifier" class="cell markdown"
id="g4x88goTBZtk">
<h3><strong>Building a Random Forest Classifier</strong></h3>
<p><strong>Random Forest is a bagging algorithm where the base models
are Decision Trees.</strong> Samples are taken from the training data
and on each sample a decision tree makes a prediction.</p>
<p><strong>The results from all the decision trees are combined together
and the final prediction is made using voting or averaging.</strong></p>
</section>
<div class="cell code" data-execution_count="14"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="64OtDSUSqbcD" data-outputId="755ae02c-4343-4a3a-d896-1f80d22f7336">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the Random Forest Classifier</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>random_forest_model <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Model on the Training Data</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>random_forest_model.fit(X_train_scaled, y_train)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the Model on the Test Set</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>y_pred_rf <span class="op">=</span> random_forest_model.predict(X_test_scaled)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the Model</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Random Forest Model Evaluation:&quot;</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Accuracy:&quot;</span>, accuracy_score(y_test, y_pred_rf))</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Confusion Matrix:&quot;</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, y_pred_rf))</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Classification Report:&quot;</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred_rf))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Random Forest Model Evaluation:
Accuracy: 0.9135906040268457

Confusion Matrix:
[[899  28]
 [ 75 190]]

Classification Report:
              precision    recall  f1-score   support

           0       0.92      0.97      0.95       927
           1       0.87      0.72      0.79       265

    accuracy                           0.91      1192
   macro avg       0.90      0.84      0.87      1192
weighted avg       0.91      0.91      0.91      1192

</code></pre>
</div>
</div>
<section id="random-forest-classifier-hyperparameter-tuning"
class="cell markdown" id="HAx1Ooocp72i">
<h3><strong>Random Forest Classifier Hyperparameter Tuning</strong></h3>
</section>
<div class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="9UQIxCZcqJHa" data-outputId="5846de72-e6b4-4b6b-8a5a-91a01e64a12b">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparameter Grid for Random Forest</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>param_grid_rf <span class="op">=</span> {</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">150</span>],</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_depth&#39;</span>: [<span class="va">None</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>],</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_leaf&#39;</span>: [<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>]</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid Search for Random Forest</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>grid_search_rf <span class="op">=</span> GridSearchCV(RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>), param_grid_rf, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>grid_search_rf.fit(X_train_scaled, y_train)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Best Hyperparameters for Random Forest</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>best_params_rf <span class="op">=</span> grid_search_rf.best_params_</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Best Hyperparameters for Random Forest:&quot;</span>, best_params_rf)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Best Hyperparameters for Random Forest: {&#39;max_depth&#39;: 20, &#39;min_samples_leaf&#39;: 1, &#39;n_estimators&#39;: 50}
</code></pre>
</div>
</div>
<div class="cell markdown" id="kPywjJo6uS-9">
<p><strong>1. Comparison of various techniques and their relative
performance based on chosen Metric (Measure of success):</strong></p>
<ul>
<li>How do different techniques perform? Which one is performing
relatively better? Is there scope to improve the performance
further?</li>
</ul>
</div>
<div class="cell markdown" id="roHZRrXv3OR3">
<p>In the assessment of different techniques for predicting loan
default, three models were considered: Logistic Regression, a single
Decision Tree, and a Random Forest Classifier. The primary metric for
evaluation was accuracy.</p>
<p>The Logistic Regression model achieved an accuracy of approximately
0.816, providing a foundational performance measure. The Decision Tree
model demonstrated an accuracy of approximately 0.865, showcasing its
ability to capture complex relationships in the data. However, the
Random Forest Classifier outperformed both, achieving the highest
accuracy of approximately 0.914. This superiority is attributed to the
ensemble nature of the Random Forest, which aggregates predictions from
multiple Decision Trees.</p>
<p>The relative performance suggests that the Random Forest Classifier
is the most effective model among the considered techniques. Further
refinement and hyperparameter tuning could potentially enhance its
performance even more.</p>
</div>
<div class="cell markdown" id="5mtOvTtEY7sM">
<p><strong>2. Refined insights:</strong></p>
<ul>
<li>What are the most meaningful insights relevant to the problem?</li>
</ul>
</div>
<div class="cell markdown" id="V0iSp8WG3P9A">
<p>Key insights emerged from the analysis, shedding light on factors
influencing loan default predictions. The loan amount was identified as
a significant variable, indicating that applicants with markedly higher
or lower loan amounts may exhibit distinct default behaviors. Job
categories demonstrated correlations with loan default rates, providing
valuable information for risk assessment based on occupation.
Additionally, the presence of derogatory reports and delinquent credit
lines appeared to impact loan default rates, emphasizing their relevance
in risk evaluation.</p>
<p>The dominance of the Random Forest Classifier in predictive accuracy
underscores the importance of ensemble methods in capturing intricate
patterns within the data.</p>
</div>
<div class="cell markdown" id="HNJHd0R7Y7sM">
<p><strong>3. Proposal for the final solution design:</strong></p>
<ul>
<li>What model do you propose to be adopted? Why is this the best
solution to adopt?</li>
</ul>
</div>
<div class="cell markdown" id="nlieu2jF3R91">
<p>The Random Forest Classifier is proposed as the best solution for
loan default prediction</p>
<p>Ensemble Advantage: The Random Forest Classifier employs an ensemble
of Decision Trees, mitigating overfitting risks and enhancing the
model's generalization capability. This ensemble approach contributes to
the model's resilience against complex patterns within the data.</p>
<p>Robust Performance: The Random Forest Classifier demonstrates the
highest accuracy of the considered techniques at 0.914.This signifies
the model's effectiveness in predicting loan default with the highest
degree of accuracy among other options.</p>
<p>Feature Importance: The Random Forest Classifier provides valuable
insights into feature importance. This attribute enhances
interpretability, allowing stakeholders to discern and prioritize key
factors influencing loan default. Understanding feature importance aids
in constructing a more informed and actionable risk assessment
strategy.</p>
<p>Potential for Further Tuning: The Random Forest model offers
flexibility for additional hyperparameter tuning. This adaptability
ensures the model remains agile and responsive to potential shifts in
the underlying data dynamics.</p>
</div>
</body>
</html>
